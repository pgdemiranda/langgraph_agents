{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Persistence and Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc114d",
   "metadata": {
    "height": 30
   },
   "source": [
    "Persistence -> Keep around the state of the agent (resuming or going back interactions)\n",
    "\n",
    "\n",
    "Streaming -> Emit a list of signals to know what's going on (what the agent is doing?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983da84",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a1774b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80704576",
   "metadata": {
    "height": 30
   },
   "source": [
    "**checkpoint** is what to help us with persistence, and it needs to be passed also on the Agent class as a **checkpointer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86bb7a",
   "metadata": {},
   "source": [
    "## Agent Class and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5c970",
   "metadata": {},
   "source": [
    "We are going to mind the streaming the individual messages and the tokens, inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a845f",
   "metadata": {},
   "source": [
    "This, threads, is a dictionary that help with the stream of the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hdl1C3zSLbpbGMErOzevVDHY', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e538461e-218b-47b8-baaa-4648ab874fac-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_hdl1C3zSLbpbGMErOzevVDHY'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_hdl1C3zSLbpbGMErOzevVDHY'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717732035, \\'localtime\\': \\'2024-06-06 20:47\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717731900, \\'last_updated\\': \\'2024-06-06 20:45\\', \\'temp_c\\': 14.4, \\'temp_f\\': 57.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 11.9, \\'wind_kph\\': 19.1, \\'wind_degree\\': 300, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1010.0, \\'pressure_in\\': 29.82, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 0, \\'feelslike_c\\': 13.1, \\'feelslike_f\\': 55.5, \\'windchill_c\\': 11.2, \\'windchill_f\\': 52.2, \\'heatindex_c\\': 12.8, \\'heatindex_f\\': 55.1, \\'dewpoint_c\\': 9.9, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 13.0, \\'vis_miles\\': 8.0, \\'uv\\': 4.0, \\'gust_mph\\': 16.5, \\'gust_kph\\': 26.6}}\"}, {\\'url\\': \\'https://forecast.weather.gov/MapClick.php?textField1=37.78&textField2=-122.42\\', \\'content\\': \\'San Francisco CA 37.77°N 122.41°W (Elev. 131 ft) Last Update: 1:31 pm PDT May 31, 2024. Forecast Valid: 7pm PDT May 31, 2024-6pm PDT Jun 7, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. Hourly Weather Forecast. ... Severe Weather ; Current Outlook Maps ; Drought ; Fire Weather ; Fronts/Precipitation Maps ...\\'}]', name='tavily_search_results_json', tool_call_id='call_hdl1C3zSLbpbGMErOzevVDHY')]\n",
      "[AIMessage(content='The current weather in San Francisco is as follows:\\n\\n- **Temperature:** 14.4°C (57.9°F)\\n- **Condition:** Clear\\n- **Wind:** 11.9 mph (19.1 kph) coming from the WNW\\n- **Humidity:** 87%\\n- **Visibility:** 13 km (8 miles)\\n\\nIt feels like 13.1°C (55.5°F) outside.', response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 727, 'total_tokens': 815}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-803871df-df47-4689-821e-c4a6536703d1-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_p1iKkCYSNSXthLj1YMlCCDCc', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 827, 'total_tokens': 849}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b2f4f2cc-dd69-4511-a73e-9219c9f78627-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_p1iKkCYSNSXthLj1YMlCCDCc'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_p1iKkCYSNSXthLj1YMlCCDCc'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717732176, \\'localtime\\': \\'2024-06-06 20:49\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717731900, \\'last_updated\\': \\'2024-06-06 20:45\\', \\'temp_c\\': 16.7, \\'temp_f\\': 62.1, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 216, \\'wind_dir\\': \\'SW\\', \\'pressure_mb\\': 1011.0, \\'pressure_in\\': 29.86, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 90, \\'cloud\\': 100, \\'feelslike_c\\': 16.7, \\'feelslike_f\\': 62.1, \\'windchill_c\\': 21.8, \\'windchill_f\\': 71.2, \\'heatindex_c\\': 22.8, \\'heatindex_f\\': 73.0, \\'dewpoint_c\\': 14.3, \\'dewpoint_f\\': 57.7, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.5, \\'gust_kph\\': 12.1}}\"}, {\\'url\\': \\'https://www.timeanddate.com/weather/usa/los-angeles/historic?month=5&year=2024\\', \\'content\\': \\'See more current weather. ... May 2024 Weather in Los Angeles — Graph °F. See Hour-by-hour Forecast for upcoming weather. See weather overview. High & Low Weather Summary for May 2024 Temperature Humidity Pressure; High: 70 °F (May 7, 11:53 am) 93% (May 5, 1:07 am) 30.08 \"Hg (May 5, 1:07 am) Low: 55 °F (May 5, 4:53 am)\\'}]', name='tavily_search_results_json', tool_call_id='call_p1iKkCYSNSXthLj1YMlCCDCc')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is as follows:\\n\\n- **Temperature:** 16.7°C (62.1°F)\\n- **Condition:** Overcast\\n- **Wind:** 2.2 mph (3.6 kph) coming from the SW\\n- **Humidity:** 90%\\n- **Visibility:** 16 km (9 miles)\\n\\nIt feels like 16.7°C (62.1°F) outside.', response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 1413, 'total_tokens': 1501}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-b706e3da-4530-48cf-9006-98620773eaf4-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Los Angeles is currently warmer than San Francisco. The temperature in Los Angeles is 16.7°C (62.1°F), while in San Francisco, it is 14.4°C (57.9°F).', response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 1513, 'total_tokens': 1558}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-822f7566-065a-493f-ae39-d2948af3ace6-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a16010",
   "metadata": {
    "height": 30
   },
   "source": [
    "When we change the **thread id**, the model is confused: it loses the context and the history of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='I can help you compare the temperatures of two locations. Please provide the names of the locations you want to compare.', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 149, 'total_tokens': 173}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-02b074fe-093e-432a-a7c9-2c239c05da49-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_Ogx0qeDOt2uDkRxXXBOn0u0C'}\n",
      "Back to the model!\n",
      "Currently|,| in| San| Francisco|:\n",
      "\n",
      "|-| **|Temperature|:**| |14|.|4|°C| (|57|.|9|°F|)\n",
      "|-| **|Condition|:**| Clear|\n",
      "|-| **|Wind|:**| |11|.|9| mph| (|19|.|1| k|ph|)| from| the| W|NW|\n",
      "|-| **|Humidity|:**| |87|%\n",
      "|-| **|Visibility|:**| |13| km| (|8| miles|)\n",
      "\n",
      "|It| feels| like| |13|.|1|°C| (|55|.|5|°F|).|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
